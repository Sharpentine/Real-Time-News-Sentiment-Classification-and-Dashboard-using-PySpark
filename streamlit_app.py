# -*- coding: utf-8 -*-
"""streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17tN9E5kYl8OeMdd2GJI20vph7zpRwa17
"""

import streamlit as st
import requests
import pandas as pd
import altair as alt
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType
from textblob import TextBlob
from typing import List, Dict

st.set_page_config(
    page_title="Real-Time News Sentiment Dashboard",
    page_icon="📰",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def get_spark_session():
    return (
        SparkSession.builder
        .appName("StreamlitSentimentApp")
        .master("local[*]")
        .getOrCreate()
    )

@st.cache_data(ttl=600) # Cache data for 10 minutes
def fetch_and_analyze_news(api_key: str, query: str) -> pd.DataFrame:

    # 1. Fetch News
    url = f'https://newsapi.org/v2/top-headlines?q={query}&language=en&pageSize=50&apiKey={api_key}'
    try:
        response = requests.get(url)
        response.raise_for_status()
        articles = response.json().get('articles', [])
        if not articles:
            st.warning("No articles found for this query.")
            return pd.DataFrame()
    except requests.exceptions.RequestException as e:
        st.error(f"Error fetching news: {e}")
        return pd.DataFrame()

    articles_to_process = [
        {"title": article.get("title"), "url": article.get("url")}
        for article in articles if article.get("title")
    ]

    spark = get_spark_session()
    news_df = spark.createDataFrame(articles_to_process)

    def classify_sentiment(text: str) -> str:
        if not text: return 'Neutral'
        polarity = TextBlob(text).sentiment.polarity
        if polarity > 0.1: return 'Positive'
        if polarity < -0.1: return 'Negative'
        return 'Neutral'

    sentiment_udf = udf(classify_sentiment, StringType())
    classified_df = news_df.withColumn("sentiment", sentiment_udf(news_df["title"]))

    return classified_df.toPandas()

st.title("📰 Real-Time News Sentiment Dashboard")
st.markdown("This dashboard fetches live news headlines, classifies them using a PySpark ML pipeline, and visualizes the sentiment distribution.")

with st.sidebar:
    st.header("⚙️ Controls")
    NEWS_API_KEY = st.secrets.get("NEWS_API_KEY", "")
    if not NEWS_API_KEY:
        NEWS_API_KEY = st.text_input("Enter your NewsAPI Key", type="password")

    query = st.text_input("Enter a news topic (e.g., AI, Tesla, finance)", "technology")

    refresh_button = st.button("Fetch and Analyze News", type="primary")

if refresh_button and NEWS_API_KEY:
    with st.spinner("Fetching news and running PySpark analysis... Please wait."):
        df = fetch_and_analyze_news(NEWS_API_KEY, query)

    if not df.empty:
        st.success(f"Successfully analyzed {len(df)} articles for '{query}'!")

        # --- Key Metrics ---
        sentiment_counts = df['sentiment'].value_counts()
        positive_count = sentiment_counts.get('Positive', 0)
        negative_count = sentiment_counts.get('Negative', 0)
        neutral_count = sentiment_counts.get('Neutral', 0)

        col1, col2, col3 = st.columns(3)
        col1.metric("Total Articles", len(df))
        col2.metric("✅ Positive", f"{positive_count}")
        col3.metric("❌ Negative", f"{negative_count}")

        # --- Visualization ---
        st.subheader("Sentiment Distribution")

        chart_data = pd.DataFrame(sentiment_counts).reset_index()
        chart_data.columns = ['sentiment', 'count']

        chart = alt.Chart(chart_data).mark_bar().encode(
            x=alt.X('sentiment', axis=alt.Axis(title='Sentiment')),
            y=alt.Y('count', axis=alt.Axis(title='Number of Articles')),
            color=alt.Color('sentiment',
                            scale=alt.Scale(
                                domain=['Positive', 'Negative', 'Neutral'],
                                range=['#2ca02c', '#d62728', '#7f7f7f']
                            )),
            tooltip=['sentiment', 'count']
        ).properties(
            title=f"Sentiment for '{query}'"
        )
        st.altair_chart(chart, use_container_width=True)

        # --- Data Table ---
        st.subheader("Analyzed Headlines")
        st.dataframe(df, use_container_width=True)
    else:
        st.error("Could not retrieve and analyze news. Check your API key or query.")
else:
    st.info("Enter your NewsAPI key and a topic, then click 'Fetch and Analyze News' to begin.")